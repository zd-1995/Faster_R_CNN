{"cells":[{"cell_type":"markdown","metadata":{},"source":["### all data collection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T17:58:49.548069Z","iopub.status.busy":"2024-04-23T17:58:49.547706Z","iopub.status.idle":"2024-04-23T18:02:05.131292Z","shell.execute_reply":"2024-04-23T18:02:05.130309Z","shell.execute_reply.started":"2024-04-23T17:58:49.548037Z"},"trusted":true},"outputs":[],"source":["# unzip model\n","\n","import zipfile\n","import os\n","\n","zip_file_p = '/kaggle/input/drone-dataset-70-20-10-edited/_output_.zip'\n","ext_to = '/kaggle/working/'\n","\n","with zipfile.ZipFile(zip_file_p, 'r') as zip_ref:\n","        zip_ref.extractall(ext_to)"]},{"cell_type":"markdown","metadata":{},"source":["### end collection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:00.897014Z","iopub.status.busy":"2024-04-23T18:13:00.896512Z","iopub.status.idle":"2024-04-23T18:13:00.905301Z","shell.execute_reply":"2024-04-23T18:13:00.904204Z","shell.execute_reply.started":"2024-04-23T18:13:00.896984Z"},"papermill":{"duration":8.366111,"end_time":"2024-03-01T22:38:57.348740","exception":false,"start_time":"2024-03-01T22:38:48.982629","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import os\n","import re\n","# import pydicom\n","import warnings\n","\n","from PIL import Image\n","import cv2\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","from albumentations.core.transforms_interface import ImageOnlyTransform\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import SequentialSampler\n","\n","from matplotlib import pyplot as plt\n","import random\n","paddingSize= 0\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","# DIR_INPUT = '/kaggle/working/Drone-1'\n","DIR_INPUT = '/kaggle/working/drone_ds'\n","DIR_TRAIN = f'{DIR_INPUT}/train'\n","DIR_VALID = f'{DIR_INPUT}/valid'\n","DIR_TEST = f'{DIR_INPUT}/test'\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:04.551303Z","iopub.status.busy":"2024-04-23T18:13:04.550809Z","iopub.status.idle":"2024-04-23T18:13:04.574943Z","shell.execute_reply":"2024-04-23T18:13:04.574002Z","shell.execute_reply.started":"2024-04-23T18:13:04.551269Z"},"trusted":true},"outputs":[],"source":["import os\n","def read_dataset(folder_path):\n","  fnames=os.listdir(f\"{folder_path}/images/\")\n","  df = pd.DataFrame()\n","  filename=[]\n","  class_num,xmin,ymin,xmax,ymax=[],[],[],[],[]\n","  for fname in fnames:\n","    if fname[-3:]== 'jpg'or fname[-3:]== 'JPG' or fname[-3:]== 'png' or fname[-3:]== 'PNG':\n","        with open(f\"{folder_path}/labels/{fname[:-3]}txt\") as f:\n","          data=f.readline()\n","          boxes= data.split()\n","          if len(boxes)==5:\n","\n","                filename.append(fname)\n","                _, x_center, y_center, width, height = map(float,boxes)\n","\n","                ymax.append(int((y_center + (height / 2))*640) +1)\n","                xmax.append(int((x_center + (width / 2))*640) +1)\n","                ymin.append(int((y_center - (height / 2))*640))\n","                xmin.append(int((x_center - (width / 2))*640))\n","            \n","                class_num.append(int(1))\n","            \n","          else:\n","#             print(f\"{filename} dosent contain box data\")\n","            \n","            filename.append(fname)\n","            ymax.append(int(640))\n","            xmax.append(int(640))\n","            ymin.append(int(0))\n","            xmin.append(int(0))\n","            class_num.append(int(0))\n","        \n","    elif fname[-4:]== 'jpeg' or fname[-4:]== 'JPEG':\n","        with open(f\"{folder_path}/labels/{fname[:-4]}txt\") as f:\n","          data=f.readline()\n","          boxes= data.split()\n","          if len(boxes)==5:\n","            filename.append(fname)\n","            _, x_center, y_center, width, height = map(float,boxes)\n"," \n","            ymax.append(int((y_center + (height / 2))*640) +1)\n","            xmax.append(int((x_center + (width / 2))*640) +1)\n","            ymin.append(int((y_center - (height / 2))*640))\n","            xmin.append(int((x_center - (width / 2))*640))\n","            \n","            class_num.append(int(1))\n","\n","          else:\n","#             print(f\"{filename} dosent contain box data\")\n","            \n","            filename.append(fname)\n","            ymax.append(int(640))\n","            xmax.append(int(640))\n","            ymin.append(int(0))\n","            xmin.append(int(0))\n","            class_num.append(int(0))\n","    else :\n","\n","        print(fname[-5:])\n","\n","        \n","\n","  df['filename']=filename\n","  df['ymax']=ymax\n","  df['ymin']=ymin\n","  df['xmax']=xmax\n","  df['xmin']=xmin\n","\n","  df['class_id']=class_num\n","    \n","  return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:09.967795Z","iopub.status.busy":"2024-04-23T18:13:09.967159Z","iopub.status.idle":"2024-04-23T18:13:14.208764Z","shell.execute_reply":"2024-04-23T18:13:14.207842Z","shell.execute_reply.started":"2024-04-23T18:13:09.967764Z"},"trusted":true},"outputs":[],"source":["train_df = read_dataset(DIR_TRAIN) #[:30]\n","print(\"df Shape: \"+str(train_df.shape))\n","\n","train_df.sort_values(by='filename').head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:20.876552Z","iopub.status.busy":"2024-04-23T18:13:20.876195Z","iopub.status.idle":"2024-04-23T18:13:24.094184Z","shell.execute_reply":"2024-04-23T18:13:24.093288Z","shell.execute_reply.started":"2024-04-23T18:13:20.876509Z"},"papermill":{"duration":0.082572,"end_time":"2024-03-01T22:38:57.711810","exception":false,"start_time":"2024-03-01T22:38:57.629238","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["valid_df = read_dataset(DIR_VALID) #[:10]\n","print(\"df Shape: \"+str(valid_df.shape))\n","\n","valid_df.sort_values(by='filename').head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:33.007417Z","iopub.status.busy":"2024-04-23T18:13:33.007095Z","iopub.status.idle":"2024-04-23T18:13:33.026795Z","shell.execute_reply":"2024-04-23T18:13:33.025822Z","shell.execute_reply.started":"2024-04-23T18:13:33.007393Z"},"papermill":{"duration":0.078777,"end_time":"2024-03-01T22:38:57.851199","exception":false,"start_time":"2024-03-01T22:38:57.772422","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class VinBigDataset(Dataset): #Class to load Training Data\n","\n","    def __init__(self, dataframe, image_dir, transforms=None,stat = 'Train'):\n","        super().__init__()\n","\n","        self.image_ids = dataframe[\"filename\"].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","        self.stat = stat\n","\n","    def __getitem__(self, index):\n","        if self.stat == 'Train':\n","\n","            image_id = self.image_ids[index]\n","            records = self.df[(self.df['filename'] == image_id)]\n","            records = records.reset_index(drop=True)\n","\n","            image = cv2.imread(f\"{self.image_dir}/images/{image_id}\")\n","\n","            try:         \n","                image = cv2.resize(image,(640,640))\n","                image = image / 255.0\n","            except Exception as e:\n","                width, height = 640, 640\n","                background_color = (0.0, 0.0, 0.0)  # White\n","\n","                # Create a blank white image\n","                image = np.full((height, width, 3), background_color, dtype=np.uint8)\n","                print(f\"{image_id}:{e}\")#, image)\n","\n","            boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n","            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","            area = torch.as_tensor(area, dtype=torch.float32)\n","            labels = torch.tensor(records[\"class_id\"].values, dtype=torch.int64)\n","\n","            # suppose all instances are not crowd\n","            iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n","\n","            target = {}\n","            target['boxes'] = boxes\n","            target['labels'] = labels\n","\n","            if self.transforms:\n","                sample = {\n","                    'image': image,\n","                    'bboxes': target['boxes'],\n","                    'labels': labels\n","                }\n","                sample = self.transforms(**sample)\n","                image = sample['image']\n","\n","                target['boxes'] = torch.tensor(sample['bboxes'])\n","\n","            if target[\"boxes\"].shape[0] == 0:\n","                # Albumentation cuts the target (class 14, 1x1px in the corner)\n","                target[\"boxes\"] = torch.from_numpy(np.array([[0.0, 0.0, 1.0, 1.0]]))\n","                # target[\"area\"] = torch.tensor([1.0], dtype=torch.float32)\n","                target[\"labels\"] = torch.tensor([0], dtype=torch.int64)\n","\n","            return image, target, image_id\n","\n","        else:\n","\n","            image_id = self.image_ids[index]\n","            records = self.df[(self.df['filename'] == image_id)]\n","            records = records.reset_index(drop=True)\n","\n","\n","            image = cv2.imread(f\"{self.image_dir}/images/{image_id}\")\n","\n","            try:\n","                image = cv2.resize(image,(640,640))\n","                image = image / 255.0\n","            except Exception as e:\n","                width, height = 640, 640\n","                background_color = (0.0, 0.0, 0.0)  # White\n","\n","                # Create a blank white image\n","                image = np.full((height, width, 3), background_color, dtype=np.uint8)\n","                print(f\"{image_id}:{e}\")#, image)\n","                \n","\n","            if self.transforms:\n","                sample = {\n","                    'image': image,\n","                }\n","                sample = self.transforms(**sample)\n","                image = sample['image']\n","\n","            return image, image_id\n","\n","    def __len__(self):\n","        return self.image_ids.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:39.430749Z","iopub.status.busy":"2024-04-23T18:13:39.429939Z","iopub.status.idle":"2024-04-23T18:13:41.531565Z","shell.execute_reply":"2024-04-23T18:13:41.530587Z","shell.execute_reply.started":"2024-04-23T18:13:39.430715Z"},"papermill":{"duration":2.40578,"end_time":"2024-03-01T22:39:00.310756","exception":false,"start_time":"2024-03-01T22:38:57.904976","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","# *\n","# model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n","# *\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#### VGG16\n","# from torchvision.models.detection import FasterRCNN\n","# from torchvision.models.detection.rpn import AnchorGenerator\n","# backbone = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT).features\n","# backbone.out_channels = 512\n","# anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),aspect_ratios=((0.5, 1.0, 2.0),))\n","# roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],output_size=7, sampling_ratio=2)\n","#  # put the pieces together inside a FasterRCNN model\n","# model = FasterRCNN(backbone,num_classes=2,rpn_anchor_generator=anchor_generator,box_roi_pool=roi_pooler)\n","# model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:45.829294Z","iopub.status.busy":"2024-04-23T18:13:45.828396Z","iopub.status.idle":"2024-04-23T18:13:45.845361Z","shell.execute_reply":"2024-04-23T18:13:45.844420Z","shell.execute_reply.started":"2024-04-23T18:13:45.829261Z"},"papermill":{"duration":0.059982,"end_time":"2024-03-01T22:39:00.425140","exception":false,"start_time":"2024-03-01T22:39:00.365158","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["num_classes = 2 # \n","\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor =  FastRCNNPredictor(in_features,num_classes)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:50.734039Z","iopub.status.busy":"2024-04-23T18:13:50.733234Z","iopub.status.idle":"2024-04-23T18:13:50.852423Z","shell.execute_reply":"2024-04-23T18:13:50.851618Z","shell.execute_reply.started":"2024-04-23T18:13:50.734009Z"},"papermill":{"duration":0.142132,"end_time":"2024-03-01T22:39:00.619260","exception":false,"start_time":"2024-03-01T22:39:00.477128","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = VinBigDataset(train_df, DIR_TRAIN, ToTensorV2(p=1.0))#, get_train_transform())\n","valid_dataset = VinBigDataset(valid_df, DIR_VALID, ToTensorV2(p=1.0))#, get_valid_transform())\n","\n","\n","# split the dataset in train and test set\n","indices = torch.randperm(len(train_dataset)).tolist()\n","# Create train and validate data loader\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size= 16 , # 8\n","    shuffle=True,\n","    num_workers=0,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size= 16 ,# 8\n","    shuffle=False,\n","    num_workers=0,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del train_df\n","del valid_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:13:57.490549Z","iopub.status.busy":"2024-04-23T18:13:57.490181Z","iopub.status.idle":"2024-04-23T18:13:59.496899Z","shell.execute_reply":"2024-04-23T18:13:59.496013Z","shell.execute_reply.started":"2024-04-23T18:13:57.490520Z"},"papermill":{"duration":1.778554,"end_time":"2024-03-01T22:39:02.448964","exception":false,"start_time":"2024-03-01T22:39:00.670410","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Train dataset sample\n","images, targets, image_ids = next(iter(train_data_loader))\n","images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","for number in random.sample([1,2,3],3):\n","#   boxes = targets[number]['boxes'].cpu().numpy().astype(np.int32)\n","  boxes = (targets[number]['boxes'].cpu().numpy()).astype(np.int32)\n","  img = images[number].permute(1,2,0).cpu().numpy()\n","  labels= targets[number]['labels'].cpu().numpy().astype(np.int32)\n","  fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","\n","  for i in range(len(boxes)):\n","      img = cv2.rectangle(img,(boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize),(255,0,0),2)\n","\n","  ax.set_axis_off()\n","  ax.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:14:16.434873Z","iopub.status.busy":"2024-04-23T18:14:16.434510Z","iopub.status.idle":"2024-04-23T18:14:16.441610Z","shell.execute_reply":"2024-04-23T18:14:16.440525Z","shell.execute_reply.started":"2024-04-23T18:14:16.434843Z"},"papermill":{"duration":0.137379,"end_time":"2024-03-01T22:39:02.664035","exception":false,"start_time":"2024-03-01T22:39:02.526656","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Averager:\n","    def __init__(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0\n","\n","    def send(self, value):\n","        self.current_total += value\n","        self.iterations += 1\n","\n","    @property\n","    def value(self):\n","        if self.iterations == 0:\n","            return 0\n","        else:\n","            return 1.0 * self.current_total / self.iterations\n","\n","    def reset(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # unzip model\n","\n","# import zipfile\n","# import os\n","\n","# zip_file_path = '/kaggle/input/faster-resnet-p11/_output_.zip'\n","# extract_to = '/kaggle/working/'\n","\n","# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","#         zip_ref.extractall(extract_to)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load Model\n","\n","# model = torch.load('/kaggle/working/resnet_bm_p11.pth')#,map_location=torch.device('cpu'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:14:21.860037Z","iopub.status.busy":"2024-04-23T18:14:21.859222Z","iopub.status.idle":"2024-04-23T18:14:21.925507Z","shell.execute_reply":"2024-04-23T18:14:21.924577Z","shell.execute_reply.started":"2024-04-23T18:14:21.860003Z"},"papermill":{"duration":0.152377,"end_time":"2024-03-01T22:39:02.901167","exception":false,"start_time":"2024-03-01T22:39:02.748790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n","\n","num_epochs = 1 #Low epoch to save GPU time"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:14:26.730787Z","iopub.status.busy":"2024-04-23T18:14:26.730195Z","iopub.status.idle":"2024-04-23T18:14:26.739687Z","shell.execute_reply":"2024-04-23T18:14:26.738850Z","shell.execute_reply.started":"2024-04-23T18:14:26.730757Z"},"trusted":true},"outputs":[],"source":["def voc_ap(rec, prec, use_07_metric=True):\n","    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n","    Compute VOC AP given precision and recall.\n","    If use_07_metric is true, uses the\n","    VOC 07 11 point method (default:True).\n","    \"\"\"\n","    if use_07_metric:\n","        # 11 point metric\n","        ap = 0.\n","        for t in np.arange(0., 1.1, 0.1):\n","            if np.sum(rec >= t) == 0:\n","                p = 0\n","            else:\n","                p = np.max(prec[rec >= t])\n","            ap = ap + p / 11.\n","    else:\n","        # correct AP calculation\n","        # first append sentinel values at the end\n","        mrec = np.concatenate(([0.], rec, [1.]))\n","        mpre = np.concatenate(([0.], prec, [0.]))\n","\n","        # compute the precision envelope\n","        for i in range(mpre.size - 1, 0, -1):\n","            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n","\n","        # to calculate area under PR curve, look for points\n","        # where X axis (recall) changes value\n","        i = np.where(mrec[1:] != mrec[:-1])[0]\n","\n","        # and sum (\\Delta recall) * prec\n","        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n","    return ap\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T18:14:34.419532Z","iopub.status.busy":"2024-04-23T18:14:34.419184Z"},"papermill":{"duration":34.2718,"end_time":"2024-03-01T22:39:37.250379","exception":false,"start_time":"2024-03-01T22:39:02.978579","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["loss_hist = Averager()\n","itr = 1\n","lossHistoryiter = []\n","lossHistoryepoch = []\n","\n","mAP_Historyepoch = []\n","\n","ovthresh=0.5\n","use_07_metric=True\n","tp = 0\n","fp = 0\n","npos = 0\n","Total_score = 0\n","Total_overlaps = 0\n","best_mAP = 0\n","\n","import time\n","start = time.time()\n","import tqdm\n","for epoch in range(num_epochs):\n","    loss_hist.reset()\n","    \n","    model.train()\n","\n","    for images, targets, image_ids in tqdm.tqdm(train_data_loader):\n","\n","        images = list(image.float().to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","#         print(type(loss_dict))\n","        losses = sum(loss for loss in loss_dict.values())\n","        loss_value = losses.item()\n","\n","        loss_hist.send(loss_value)\n","        lossHistoryiter.append(loss_value)\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","        \n","        if itr % 50 == 0:\n","            print(f\"Iteration #{itr} loss: {loss_value}\",end=\"\\r\")\n","        itr += 1\n","\n","    # update the learning rate\n","    if lr_scheduler is not None:\n","        lr_scheduler.step()\n","    lossHistoryepoch.append(loss_hist.value)\n","    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")\n","    \n","    ## Validation\n","    model.eval()\n","    cpu_device = torch.device(\"cpu\")\n","\n","    for images, targets, image_ids in tqdm.tqdm(valid_data_loader):\n","        images = list(image.float().to(device) for image in images)\n","    \n","\n","        with torch.no_grad():\n","            outputs = model(images)\n","\n","        for tar,out in zip(targets,outputs):\n","    \n","            score = out['scores'].sum().cpu().detach().numpy()\n","\n","            bb = tar['boxes'].cpu().detach().numpy()\n","            BBGT = out['boxes'].cpu().detach().numpy()\n","            ixmin = np.maximum(BBGT[:, 0], bb[0,0])\n","            iymin = np.maximum(BBGT[:, 1], bb[0,1])\n","            ixmax = np.minimum(BBGT[:, 2], bb[0,2])\n","            iymax = np.minimum(BBGT[:, 3], bb[0,3])\n","            iw = np.maximum(ixmax - ixmin, 0.)\n","            ih = np.maximum(iymax - iymin, 0.)\n","            inters = iw * ih\n","            uni = ((bb[0,2] - bb[0,0]) * (bb[0,3] - bb[0,1]) +\n","                    (BBGT[:, 2] - BBGT[:, 0]) *\n","                    (BBGT[:, 3] - BBGT[:, 1]) - inters)\n","            overlaps = inters / uni\n","    #         print(overlaps)\n","\n","            if overlaps.size==0:\n","                continue\n"," \n","            ovmax = np.max(overlaps)\n","            jmax = np.argmax(overlaps)\n","            if ovmax > ovthresh:\n","                tp+=1\n","            else:\n","                fp+=1\n","            npos+=bb.shape[0]\n","    rec = tp / float(npos)\n","    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n","    ap = voc_ap(rec, prec, use_07_metric)\n","    print(f\"Epoch #{epoch} mAP: {ap}\")\n","    mAP_Historyepoch.append(ap)\n","        \n","    # save best validation\n","    if best_mAP<ap:\n","        torch.save(model, '/kaggle/working/resnet_bm_p12.pth')\n","        best_mAP = ap\n","\n","end = time.time()\n","hours, rem = divmod(end-start, 3600)\n","minutes, seconds = divmod(rem, 60)\n","print(\"Time taken to Train the model :{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot training loss\n","import matplotlib.pyplot as plt\n","\n","y = lossHistoryepoch\n","\n","# Plot scatter plot of training loss\n","x = np.arange(1, num_epochs+1)\n","colors = y  # Use loss values as colors\n","\n","plt.plot(x, y, marker='o', linestyle='-')#, color=plt.cm.viridis(colors))\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot validation mAP\n","import matplotlib.pyplot as plt\n","\n","z = mAP_Historyepoch\n","\n","# Plot scatter plot of training loss\n","x = np.arange(1, num_epochs+1)\n","colors = y  # Use loss values as colors\n","\n","plt.plot(x, z, marker='o', linestyle='-')#, color=plt.cm.viridis(colors))\n","plt.xlabel('Epoch')\n","plt.ylabel('mAP')\n","plt.title('Validation mAP')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.107572,"end_time":"2024-03-01T22:39:39.580796","exception":false,"start_time":"2024-03-01T22:39:39.473224","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["DIR_TEST = f'{DIR_INPUT}/test'\n","\n","test_df = read_dataset(DIR_TEST) \n","print(\"df Shape: \"+str(test_df.shape))\n","\n","test_df.sort_values(by='filename').head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.088854,"end_time":"2024-03-01T22:39:39.748180","exception":false,"start_time":"2024-03-01T22:39:39.659326","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["model.eval()\n","cpu_device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.086948,"end_time":"2024-03-01T22:39:39.913719","exception":false,"start_time":"2024-03-01T22:39:39.826771","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_dataset = VinBigDataset(test_df, DIR_TEST, ToTensorV2(p=1.0))#,\"Test\")\n","\n","test_data_loader = DataLoader(\n","    test_dataset,\n","    batch_size= 16, # 8\n","    shuffle=False,\n","    num_workers=0,\n","    drop_last=False,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.088009,"end_time":"2024-03-01T22:39:40.078707","exception":false,"start_time":"2024-03-01T22:39:39.990698","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def format_prediction_string(labels, boxes, scores):\n","    pred_strings = []\n","    for j in zip(labels, scores, boxes):\n","        pred_strings.append(\"{0} {1:.4f} {2} {3} {4} {5}\".format(\n","            j[0], j[1], j[2][0], j[2][1], j[2][2], j[2][3]))\n","\n","    return \" \".join(pred_strings)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":1.589216,"end_time":"2024-03-01T22:39:41.745029","exception":false,"start_time":"2024-03-01T22:39:40.155813","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Test dataset sample\n","images,target, image_ids = next(iter(test_data_loader))\n","images = list(image.to(device) for image in images)\n","\n","for number in random.sample([1,2,3],3):\n","  img = images[number].permute(1,2,0).cpu().numpy()\n","  fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","  ax.set_axis_off()\n","  ax.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":1.479842,"end_time":"2024-03-01T22:39:43.322727","exception":false,"start_time":"2024-03-01T22:39:41.842885","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["### Test images\n","images,target, image_ids = next(iter(test_data_loader))\n","images = list(img.float().to(device) for img in images)\n","\n","outputs = model(images)\n","outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n","\n","\n","boxes = outputs[0]['boxes'].cpu().detach().numpy().astype(np.int32)\n","img = images[0].permute(1,2,0).cpu().detach().numpy()\n","labels= outputs[0]['labels'].cpu().detach().numpy().astype(np.int32)\n","score = outputs[0]['scores']\n","# print(score)\n","\n","fig, ax = plt.subplots(1,1,figsize=(16, 8))\n","\n","img = cv2.cvtColor(np.float32(img), cv2.COLOR_RGB2BGR)\n","for i in range(len(boxes)):\n","  img = cv2.rectangle(img,(boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize),(255,0,0),2)\n","  #print(le.inverse_transform([labels[i]-1])[0])\n","#   print(label_to_name(labels[i]), (boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize))\n","  # img = cv2.putText(img, label_to_name(labels[i]), (int(boxes[i][0]), int(boxes[i][1])), cv2.FONT_HERSHEY_TRIPLEX,3, (255,0,0), 3, cv2.LINE_AA)\n","t_boxes = target[0]['boxes'].cpu().detach().numpy().astype(np.int32)\n","for i in range(len(t_boxes)):\n","  img = cv2.rectangle(img,(t_boxes[i][0]+paddingSize,t_boxes[i][1]+paddingSize),(t_boxes[i][2]+paddingSize,t_boxes[i][3]+paddingSize),(0,0,255),2)\n","  \n","ax.set_axis_off()\n","ax.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":7.697966,"end_time":"2024-03-01T22:39:51.390706","exception":false,"start_time":"2024-03-01T22:39:43.692740","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import time\n","import tqdm\n","\n","ovthresh=0.5\n","use_07_metric=True\n","tp = 0\n","fp = 0\n","npos = 0\n","\n","\n","\n","Total_score = 0\n","Total_score_2 = 0\n","Total_overlaps = 0\n","start = time.time()\n","for images, targets, image_ids in tqdm.tqdm(test_data_loader):\n","    images = list(image.float().to(device) for image in images)\n","\n","    with torch.no_grad():\n","        outputs = model(images)\n","        \n","    for tar,out in zip(targets,outputs):\n","#         print(tar['boxes'].size(),out['boxes'].size())\n","        score = out['scores'].sum().cpu().detach().numpy()\n","        score_2 = out['scores'].mean().cpu().detach().numpy()\n","\n","        \n","        bb = tar['boxes'].cpu().detach().numpy()\n","        BBGT = out['boxes'].cpu().detach().numpy()\n","        ixmin = np.maximum(BBGT[:, 0], bb[0,0])\n","        iymin = np.maximum(BBGT[:, 1], bb[0,1])\n","        ixmax = np.minimum(BBGT[:, 2], bb[0,2])\n","        iymax = np.minimum(BBGT[:, 3], bb[0,3])\n","        iw = np.maximum(ixmax - ixmin, 0.)\n","        ih = np.maximum(iymax - iymin, 0.)\n","        inters = iw * ih\n","        uni = ((bb[0,2] - bb[0,0]) * (bb[0,3] - bb[0,1]) +\n","                (BBGT[:, 2] - BBGT[:, 0]) *\n","                (BBGT[:, 3] - BBGT[:, 1]) - inters)\n","        overlaps = inters / uni\n","#         print(overlaps)\n","        Total_overlaps = Total_overlaps + overlaps.sum()\n","        \n","        if overlaps.size==0:\n","\n","            continue\n","\n","        Total_score = Total_score + score\n","        Total_score_2 = Total_score_2 + score_2\n","        ovmax = np.max(overlaps)\n","        jmax = np.argmax(overlaps)\n","        if ovmax > ovthresh:\n","            tp+=1\n","        else:\n","            fp+=1\n","        npos+=bb.shape[0]\n","        \n","\n","end = time.time()\n","hours, rem = divmod(end-start, 3600)\n","minutes, seconds = divmod(rem, 60)\n","print(\"Time taken to Test the model :{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n","\n","rec = tp / float(npos)\n","prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n","ap = voc_ap(rec, prec, use_07_metric)\n","IOU = Total_overlaps/npos\n","confidence = Total_score/npos"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.120741,"end_time":"2024-03-01T22:39:51.623227","exception":false,"start_time":"2024-03-01T22:39:51.502486","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["print('mean average precision:',ap)\n","print('confidence_2:',Total_score_2/npos)\n","print('confidence :',confidence)\n","print(\"IoU:\", IOU)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":1.479842,"end_time":"2024-03-01T22:39:43.322727","exception":false,"start_time":"2024-03-01T22:39:41.842885","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","'''\n","\n","### predict images\n","\n","folder_path = '/kaggle/input/imagefortest'\n","\n","# Get list of files in the folder\n","file_list = os.listdir(folder_path)\n","\n","# Read each image in the folder\n","list_image = []\n","for file_name in file_list:\n","#     if file_name.endswith('.jpg') or file_name.endswith('.png'):\n","        image_path = os.path.join(folder_path, file_name)\n","#         print(image_path)\n","        image = cv2.imread(image_path)\n","        if image is not None:\n","            list_image.append(image)\n","# print(len(list_image))\n","counter = 1\n","print(len(list_image))\n","for images in tqdm.tqdm(list_image):\n","    image = torch.tensor(images).to(device)\n","    image = image/255.0\n","    image = image.unsqueeze(0)\n","    image = image.permute(0,3,1,2)\n","#     image = image.squeeze(0)\n","    \n","#     images.to(device)\n","    start = time.time()\n","#     outputs = model(image)\n","    \n","    with torch.no_grad():\n","        outputs = model(image)\n","    print(len(outputs[0]))\n","    outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n","    end = time.time()\n","    \n","    hours, rem = divmod(end-start, 3600)\n","    minutes, seconds = divmod(rem, 60)\n","    print('Number :',counter )\n","    print(\"Time taken to per image the model :{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n","\n","    boxes = outputs[0]['boxes'].cpu().detach().numpy().astype(np.int32)\n","    img = image.permute(0,2,3,1).cpu().detach().numpy()\n","    img = img.squeeze(0)\n","    labels= outputs[0]['labels'].cpu().detach().numpy().astype(np.int32)\n","    score = outputs[0]['scores'].cpu().detach().numpy()\n","    print('label:',labels ,'-  score:', score)\n","    \n","\n","    fig, ax = plt.subplots(1, 1)#, figsize=(8, 5))\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    img = cv2.cvtColor(np.float32(img), cv2.COLOR_RGB2BGR)\n","    for i in range(len(boxes)):\n","      if score[i]>0.20: \n","        img = cv2.rectangle(img,(boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize),(0,255,0),2)\n","        img = cv2.putText(img,str(score[i]),(boxes[i][0]+paddingSize,boxes[i][1]+paddingSize-10),font,0.5,(0,255,0),1)\n","\n","    ax.set_axis_off()\n","    ax.imshow(img)\n","    fig.savefig(f'{counter}.jpeg',dpi = 600)\n","    \n","    counter = counter + 1\n","    \n","    \n","'''"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":171866446,"sourceType":"kernelVersion"},{"sourceId":174609515,"sourceType":"kernelVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}

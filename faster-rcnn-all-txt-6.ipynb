{"cells":[{"cell_type":"markdown","metadata":{},"source":["### all data collection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T12:08:28.866501Z","iopub.status.busy":"2024-04-19T12:08:28.865904Z","iopub.status.idle":"2024-04-19T12:08:28.874630Z","shell.execute_reply":"2024-04-19T12:08:28.873602Z","shell.execute_reply.started":"2024-04-19T12:08:28.866468Z"},"trusted":true},"outputs":[],"source":["#-- Create directory structure as follows:\n","'''\n","done_ds:\n","    train:\n","        images\n","        labels\n","\n","    valid:\n","        images\n","        labels\n","\n","    test:\n","        images\n","        labels\n","'''\n","import os\n","import shutil\n","\n","\n","#-- Create Empty folders -------------------------------------------------------------\n","\n","#-- Define the path for the main folder --\n","main_folder = 'drone_ds'\n","\n","#-- Define subfolders --\n","subfolders = ['train', 'valid', 'test']\n","subsubfolders = ['images', 'labels']\n","\n","#-- save created directories as a dict --\n","dir_dict = {}\n","\n","#-- Create the main folder --\n","os.makedirs(main_folder, exist_ok=True)\n","\n","#-- Create subfolders and sub-subfolders --\n","for folder in subfolders:\n","    os.makedirs(os.path.join(main_folder, folder), exist_ok=True)\n","   \n","    for subfolder in subsubfolders:\n","        new_dir = os.path.join(main_folder, folder, subfolder)\n","        os.makedirs(new_dir, exist_ok=True)\n","        dir_dict[(folder,subfolder)] = new_dir\n","\n","\n","# print(dir_dict)\n","#--------------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T12:23:47.901399Z","iopub.status.busy":"2024-04-19T12:23:47.901024Z","iopub.status.idle":"2024-04-19T12:28:42.864155Z","shell.execute_reply":"2024-04-19T12:28:42.863147Z","shell.execute_reply.started":"2024-04-19T12:23:47.901369Z"},"trusted":true},"outputs":[],"source":["#-- fild paths for images and labeles --------------------------------------------------\n","def find_paths(directory, extensions):\n","    \n","    file_paths = set() \n","    \n","    #-- Walk through the directory tree --\n","    for root, _, files in os.walk(directory):        \n","        for file in files:            \n","            if any(file.endswith(ext) for ext in extensions):\n","                file_paths.add(root)                \n","                break\n","    \n","    return file_paths\n","#--------------------------------------------------------------------------------------\n","\n","#-- find all paths for images and labels ----------------------------------------------\n","\n","#-- Define the directory to search in --\n","directory_to_search = '/kaggle/input'\n","\n","#-- Define the file extensions you want to search for --\n","image_extensions = {'.jpg', '.jpeg', '.png', '.JPEG'}  \n","text_extensions = {'.txt'}  \n","\n","#-- Find paths to image files --\n","images_paths = find_paths(directory_to_search, image_extensions)\n","\n","#-- Find paths to label files --\n","labels_paths = find_paths(directory_to_search, text_extensions)\n","\n","#-- Print the paths --\n","print(\"Image paths:\")\n","for img_path in images_paths:\n","    print(img_path)\n","\n","print(\"\\nText paths:\")\n","for lbl_path in labels_paths:\n","    print(lbl_path)\n","#--------------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T12:31:43.284084Z","iopub.status.busy":"2024-04-19T12:31:43.283658Z","iopub.status.idle":"2024-04-19T13:06:58.481743Z","shell.execute_reply":"2024-04-19T13:06:58.480927Z","shell.execute_reply.started":"2024-04-19T12:31:43.284054Z"},"trusted":true},"outputs":[],"source":["#-- Copy all images and labels from input to drone_ds folder ----------------------------\n","\n","tags = ['train', 'valid', 'test']\n","\n","#-- copy images --\n","for img_path in images_paths:\n","    if 'train' in img_path or 'test' in img_path or 'valid' in img_path:\n","        if 'train' in img_path: \n","            tag = 'train'\n","\n","        elif 'valid' in img_path: \n","            tag = 'valid'\n","\n","        elif 'test' in img_path: \n","            tag = 'test'\n","         \n","        \n","        #-- log --\n","        print(f'copy {tag} images from {img_path} ---- ')\n","\n","        #-- set source and destination --\n","        source_dir = img_path\n","        dest_dir = dir_dict[(tag,'images')]\n","\n","        #-- copy images --\n","        files = os.listdir(source_dir)            \n","        for file in files:\n","            source_file_path = os.path.join(source_dir, file)\n","            destination_file_path = os.path.join(dest_dir, file)\n","            shutil.copy(source_file_path, destination_file_path)\n","\n","\n","\n","#-- copy labels --\n","for lbl_path in labels_paths:\n","    if 'train' in lbl_path or 'test' in lbl_path or 'valid' in lbl_path:\n","        if 'train' in lbl_path: \n","            tag = 'train'\n","\n","        elif 'valid' in lbl_path: \n","            tag = 'valid'\n","\n","        elif 'test' in lbl_path: \n","            tag = 'test'\n","        \n","            \n","        #-- log --\n","        print(f'copy {tag} labels from {lbl_path} ---- ')\n","\n","        #-- set source and destination --\n","        source_dir = lbl_path\n","        dest_dir = dir_dict[(tag,'labels')]\n","\n","        #-- copy images --\n","        files = os.listdir(source_dir)            \n","        for file in files:\n","            source_file_path = os.path.join(source_dir, file)\n","            destination_file_path = os.path.join(dest_dir, file)\n","            shutil.copy(source_file_path, destination_file_path)\n","#--------------------------------------------------------------------------------------    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:09:47.903643Z","iopub.status.busy":"2024-04-19T13:09:47.902938Z","iopub.status.idle":"2024-04-19T13:37:36.592586Z","shell.execute_reply":"2024-04-19T13:37:36.591665Z","shell.execute_reply.started":"2024-04-19T13:09:47.903613Z"},"trusted":true},"outputs":[],"source":["import os \n","import random\n","import shutil\n","\n","random.seed(0)\n","\n","tags = ['train', 'valid', 'test']\n","image_divide_path = []\n","label_divide_path = []\n","\n","#         if 'train' not in img and 'test' not in img and 'valid' not in img:\n","#         if 'train' not in lbl and 'test' not in lbl and 'valid' not in lbl:\n","\n","#-- copy images --\n","for img_path in images_paths:\n","    if 'train' not in img_path and 'test' not in img_path and 'valid' not in img_path:\n","        print(img_path)\n","        images = os.listdir(img_path)\n","        print(len(images))\n","        for img in images:\n","            image_path = os.path.join(img_path, img)\n","            image_divide_path.append(image_path)\n","        \n","for lbl_path in labels_paths:\n","    if 'train' not in lbl_path and 'test' not in lbl_path and 'valid' not in lbl_path:\n","        print(lbl_path)\n","        labels = os.listdir(lbl_path)\n","        print(len(labels))\n","        for lbl in labels:\n","            label_path = os.path.join(lbl_path, lbl)\n","            label_divide_path.append(label_path)\n","# Shuffle the list to randomize the order\n","\n","random.shuffle(image_divide_path)\n","\n","# Calculate the number of files for each group\n","total_files = len(image_divide_path)\n","train_count = int(total_files * 0.70)\n","valid_count = int(total_files * 0.20)\n","test_count = total_files - train_count - valid_count\n","\n","image_label_map = {}\n","for image_path in image_divide_path:\n","    image_name = os.path.splitext(os.path.basename(image_path))[0]\n","    for label_path in label_divide_path:\n","        label_name = os.path.splitext(os.path.basename(label_path))[0]\n","        if image_name == label_name:\n","            image_label_map[image_path] = label_path\n","            break\n","# print(\"dictionary made\")\n","# Use the image_label_map to copy files to the appropriate folders\n","for i, image_path in enumerate(image_label_map.keys()):#image_divide_path\n","    if i < train_count:\n","        dest_dir = dir_dict[('train','images')]\n","        dest_dir_lbl = dir_dict[('train','labels')]\n","    elif i < train_count + valid_count:\n","        dest_dir = dir_dict[('valid','images')]\n","        dest_dir_lbl = dir_dict[('valid','labels')]\n","    else:\n","        dest_dir = dir_dict[('test','images')]\n","        dest_dir_lbl = dir_dict[('test','labels')]\n","\n","    shutil.copy(image_path, dest_dir)\n","    shutil.copy(image_label_map[image_path], dest_dir_lbl)\n","# print(\"the directories made\")"]},{"cell_type":"markdown","metadata":{},"source":["### end collection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:37:50.474435Z","iopub.status.busy":"2024-04-19T13:37:50.473980Z","iopub.status.idle":"2024-04-19T13:38:02.122750Z","shell.execute_reply":"2024-04-19T13:38:02.121964Z","shell.execute_reply.started":"2024-04-19T13:37:50.474406Z"},"papermill":{"duration":8.366111,"end_time":"2024-03-01T22:38:57.348740","exception":false,"start_time":"2024-03-01T22:38:48.982629","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import os\n","import re\n","# import pydicom\n","import warnings\n","\n","from PIL import Image\n","import cv2\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","from albumentations.core.transforms_interface import ImageOnlyTransform\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import SequentialSampler\n","\n","from matplotlib import pyplot as plt\n","import random\n","paddingSize= 0\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","# DIR_INPUT = '/kaggle/working/Drone-1'\n","DIR_INPUT = '/kaggle/working/drone_ds'\n","DIR_TRAIN = f'{DIR_INPUT}/train'\n","DIR_VALID = f'{DIR_INPUT}/valid'\n","DIR_TEST = f'{DIR_INPUT}/test'\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:07.168371Z","iopub.status.busy":"2024-04-19T13:38:07.167438Z","iopub.status.idle":"2024-04-19T13:38:07.185575Z","shell.execute_reply":"2024-04-19T13:38:07.184586Z","shell.execute_reply.started":"2024-04-19T13:38:07.168336Z"},"trusted":true},"outputs":[],"source":["import os\n","def read_dataset(folder_path):\n","  fnames=os.listdir(f\"{folder_path}/images/\")\n","  df = pd.DataFrame()\n","  filename=[]\n","  class_num,xmin,ymin,xmax,ymax=[],[],[],[],[]\n","  for fname in fnames:\n","    if fname[-3:]== 'jpg'or fname[-3:]== 'JPG' or fname[-3:]== 'png' or fname[-3:]== 'PNG':\n","        with open(f\"{folder_path}/labels/{fname[:-3]}txt\") as f:\n","          data=f.readline()\n","          boxes= data.split()\n","          if len(boxes)==5:\n","#             if fname=='bird_44.jpg':\n","#                 print(\"here\")\n","#             else:\n","                filename.append(fname)\n","                _, x_center, y_center, width, height = map(float,boxes)\n","            ##### check for 0 ymax and xmax\n","#             if (int((y_center + (height / 2))*640))<=0 or (int((x_center + (width / 2))*640))<=0:\n","#               print(data,'file:',fname)\n","            #####\n","                ymax.append(int((y_center + (height / 2))*640) +1)\n","                xmax.append(int((x_center + (width / 2))*640) +1)\n","                ymin.append(int((y_center - (height / 2))*640))\n","                xmin.append(int((x_center - (width / 2))*640))\n","            \n","                class_num.append(int(1))\n","            \n","          else:\n","#             print(f\"{filename} dosent contain box data\")\n","            \n","            filename.append(fname)\n","            ymax.append(int(640))\n","            xmax.append(int(640))\n","            ymin.append(int(0))\n","            xmin.append(int(0))\n","            class_num.append(int(0))\n","        \n","    elif fname[-4:]== 'jpeg' or fname[-4:]== 'JPEG':\n","        with open(f\"{folder_path}/labels/{fname[:-4]}txt\") as f:\n","          data=f.readline()\n","          boxes= data.split()\n","          if len(boxes)==5:\n","            filename.append(fname)\n","            _, x_center, y_center, width, height = map(float,boxes)\n","            ##### check for 0 ymax and xmax\n","#             if (int((y_center + (height / 2))*640))<=0 or (int((x_center + (width / 2))*640))<=0:\n","#               print(data,'file:',fname)\n","            ######\n","            ymax.append(int((y_center + (height / 2))*640) +1)\n","            xmax.append(int((x_center + (width / 2))*640) +1)\n","            ymin.append(int((y_center - (height / 2))*640))\n","            xmin.append(int((x_center - (width / 2))*640))\n","            \n","            class_num.append(int(1))\n","\n","          else:\n","#             print(f\"{filename} dosent contain box data\")\n","            \n","            filename.append(fname)\n","            ymax.append(int(640))\n","            xmax.append(int(640))\n","            ymin.append(int(0))\n","            xmin.append(int(0))\n","            class_num.append(int(0))\n","    else :\n","#         continue\n","        print(fname[-5:])\n","##_______\n","\n","##_______\n","        \n","        \n","\n","  df['filename']=filename\n","  df['ymax']=ymax\n","  df['ymin']=ymin\n","  df['xmax']=xmax\n","  df['xmin']=xmin\n","####\n","  df['class_id']=class_num\n","    \n","  return df\n","# testing_df = read_dataset(DIR_TRAIN)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:12.117419Z","iopub.status.busy":"2024-04-19T13:38:12.116578Z","iopub.status.idle":"2024-04-19T13:38:16.400320Z","shell.execute_reply":"2024-04-19T13:38:16.399307Z","shell.execute_reply.started":"2024-04-19T13:38:12.117385Z"},"trusted":true},"outputs":[],"source":["# train_df = pd.read_csv(f'{DIR_TRAIN}/_annotations.csv') #[:100]\n","train_df = read_dataset(DIR_TRAIN) #[:30]\n","print(\"df Shape: \"+str(train_df.shape))\n","# print(\"No Of Classes: \"+str(train_df[\"class\"].nunique()))\n","# train_df['class_id']=1\n","train_df.sort_values(by='filename').head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:32.368510Z","iopub.status.busy":"2024-04-19T13:38:32.367630Z","iopub.status.idle":"2024-04-19T13:38:32.820390Z","shell.execute_reply":"2024-04-19T13:38:32.819348Z","shell.execute_reply.started":"2024-04-19T13:38:32.368476Z"},"papermill":{"duration":0.082572,"end_time":"2024-03-01T22:38:57.711810","exception":false,"start_time":"2024-03-01T22:38:57.629238","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# valid_df = pd.read_csv(f'{DIR_VALID}/_annotations.csv')#[:100]\n","valid_df = read_dataset(DIR_VALID) #[:10]\n","print(\"df Shape: \"+str(valid_df.shape))\n","# print(\"No Of Classes: \"+str(valid_df[\"class\"].nunique()))\n","# valid_df['class_id']=1\n","valid_df.sort_values(by='filename').head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:36.563638Z","iopub.status.busy":"2024-04-19T13:38:36.563143Z","iopub.status.idle":"2024-04-19T13:38:36.583920Z","shell.execute_reply":"2024-04-19T13:38:36.582970Z","shell.execute_reply.started":"2024-04-19T13:38:36.563609Z"},"papermill":{"duration":0.078777,"end_time":"2024-03-01T22:38:57.851199","exception":false,"start_time":"2024-03-01T22:38:57.772422","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Thanks -  https://www.kaggle.com/pestipeti/\n","class VinBigDataset(Dataset): #Class to load Training Data\n","\n","    def __init__(self, dataframe, image_dir, transforms=None,stat = 'Train'):\n","        super().__init__()\n","\n","        self.image_ids = dataframe[\"filename\"].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","        self.stat = stat\n","\n","    def __getitem__(self, index):\n","        if self.stat == 'Train':\n","\n","            image_id = self.image_ids[index]\n","            records = self.df[(self.df['filename'] == image_id)]\n","            records = records.reset_index(drop=True)\n","\n","            image = cv2.imread(f\"{self.image_dir}/images/{image_id}\")\n","\n","            try:         \n","                image = cv2.resize(image,(640,640))\n","                image = image / 255.0\n","            except Exception as e:\n","                width, height = 640, 640\n","                background_color = (0.0, 0.0, 0.0)  # White\n","\n","                # Create a blank white image\n","                image = np.full((height, width, 3), background_color, dtype=np.uint8)\n","                print(f\"{image_id}:{e}\")#, image)\n","#                 continue\n","                \n","\n","            boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n","            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","            area = torch.as_tensor(area, dtype=torch.float32)\n","            labels = torch.tensor(records[\"class_id\"].values, dtype=torch.int64)\n","\n","            # suppose all instances are not crowd\n","            iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n","\n","            target = {}\n","            target['boxes'] = boxes\n","            target['labels'] = labels\n","\n","\n","            if self.transforms:\n","                sample = {\n","                    'image': image,\n","                    'bboxes': target['boxes'],\n","                    'labels': labels\n","                }\n","                sample = self.transforms(**sample)\n","                image = sample['image']\n","\n","                target['boxes'] = torch.tensor(sample['bboxes'])\n","\n","            if target[\"boxes\"].shape[0] == 0:\n","                # Albumentation cuts the target (class 14, 1x1px in the corner)\n","                target[\"boxes\"] = torch.from_numpy(np.array([[0.0, 0.0, 1.0, 1.0]]))\n","                # target[\"area\"] = torch.tensor([1.0], dtype=torch.float32)\n","                target[\"labels\"] = torch.tensor([0], dtype=torch.int64)\n","\n","            return image, target, image_id\n","\n","        else:\n","\n","            image_id = self.image_ids[index]\n","            records = self.df[(self.df['filename'] == image_id)]\n","            records = records.reset_index(drop=True)\n","\n","\n","            image = cv2.imread(f\"{self.image_dir}/images/{image_id}\")\n","\n","            try:\n","                image = cv2.resize(image,(640,640))\n","                image = image / 255.0\n","            except Exception as e:\n","                width, height = 640, 640\n","                background_color = (0.0, 0.0, 0.0)  # White\n","\n","                # Create a blank white image\n","                image = np.full((height, width, 3), background_color, dtype=np.uint8)\n","                print(f\"{image_id}:{e}\")#, image)\n","                \n","\n","            if self.transforms:\n","                sample = {\n","                    'image': image,\n","                }\n","                sample = self.transforms(**sample)\n","                image = sample['image']\n","\n","            return image, image_id\n","\n","    def __len__(self):\n","        return self.image_ids.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:43.357347Z","iopub.status.busy":"2024-04-19T13:38:43.356494Z","iopub.status.idle":"2024-04-19T13:38:44.613269Z","shell.execute_reply":"2024-04-19T13:38:44.612251Z","shell.execute_reply.started":"2024-04-19T13:38:43.357315Z"},"papermill":{"duration":2.40578,"end_time":"2024-03-01T22:39:00.310756","exception":false,"start_time":"2024-03-01T22:38:57.904976","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import torchvision\n","\n","\n","# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","# *\n","model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n","# *"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T12:32:11.332790Z","iopub.status.busy":"2024-04-02T12:32:11.332439Z","iopub.status.idle":"2024-04-02T12:32:17.129449Z","shell.execute_reply":"2024-04-02T12:32:17.128552Z","shell.execute_reply.started":"2024-04-02T12:32:11.332763Z"},"trusted":true},"outputs":[],"source":["#### VGG16\n","# from torchvision.models.detection import FasterRCNN\n","# from torchvision.models.detection.rpn import AnchorGenerator\n","# backbone = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT).features\n","# backbone.out_channels = 512\n","# anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),aspect_ratios=((0.5, 1.0, 2.0),))\n","# roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],output_size=7, sampling_ratio=2)\n","#  # put the pieces together inside a FasterRCNN model\n","# model = FasterRCNN(backbone,num_classes=2,rpn_anchor_generator=anchor_generator,box_roi_pool=roi_pooler)\n","# model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:47.771715Z","iopub.status.busy":"2024-04-19T13:38:47.771322Z","iopub.status.idle":"2024-04-19T13:38:47.777559Z","shell.execute_reply":"2024-04-19T13:38:47.776701Z","shell.execute_reply.started":"2024-04-19T13:38:47.771685Z"},"papermill":{"duration":0.059982,"end_time":"2024-03-01T22:39:00.425140","exception":false,"start_time":"2024-03-01T22:39:00.365158","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["num_classes = 2 # \n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor =  FastRCNNPredictor(in_features,num_classes)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:51.251952Z","iopub.status.busy":"2024-04-19T13:38:51.251556Z","iopub.status.idle":"2024-04-19T13:38:51.352129Z","shell.execute_reply":"2024-04-19T13:38:51.351160Z","shell.execute_reply.started":"2024-04-19T13:38:51.251921Z"},"papermill":{"duration":0.142132,"end_time":"2024-03-01T22:39:00.619260","exception":false,"start_time":"2024-03-01T22:39:00.477128","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = VinBigDataset(train_df, DIR_TRAIN, ToTensorV2(p=1.0))#, get_train_transform())\n","valid_dataset = VinBigDataset(valid_df, DIR_VALID, ToTensorV2(p=1.0))#, get_valid_transform())\n","\n","\n","# split the dataset in train and test set\n","indices = torch.randperm(len(train_dataset)).tolist()\n","# Create train and validate data loader\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size= 8 , # 8\n","    shuffle=True,\n","    num_workers=0,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size= 8,# 8\n","    shuffle=False,\n","    num_workers=0,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T12:38:23.024754Z","iopub.status.busy":"2024-04-02T12:38:23.024012Z","iopub.status.idle":"2024-04-02T12:38:23.057734Z","shell.execute_reply":"2024-04-02T12:38:23.056437Z","shell.execute_reply.started":"2024-04-02T12:38:23.024721Z"},"trusted":true},"outputs":[],"source":["del train_df\n","del valid_df\n","# del valid_data_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:38:55.966021Z","iopub.status.busy":"2024-04-19T13:38:55.965193Z","iopub.status.idle":"2024-04-19T13:38:58.108792Z","shell.execute_reply":"2024-04-19T13:38:58.107816Z","shell.execute_reply.started":"2024-04-19T13:38:55.965989Z"},"papermill":{"duration":1.778554,"end_time":"2024-03-01T22:39:02.448964","exception":false,"start_time":"2024-03-01T22:39:00.670410","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Train dataset sample\n","images, targets, image_ids = next(iter(train_data_loader))\n","images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","for number in random.sample([1,2,3],3):\n","#   boxes = targets[number]['boxes'].cpu().numpy().astype(np.int32)\n","  boxes = (targets[number]['boxes'].cpu().numpy()).astype(np.int32)\n","  img = images[number].permute(1,2,0).cpu().numpy()\n","  labels= targets[number]['labels'].cpu().numpy().astype(np.int32)\n","  fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","\n","  for i in range(len(boxes)):\n","      img = cv2.rectangle(img,(boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize),(255,0,0),2)\n","      #print(le.inverse_transform([labels[i]-1])[0])\n","      #print(label_to_name(labels[i]), (int(boxes[i][0]), int(boxes[i][1])))\n","      # img = cv2.putText(img, labels[i], (int(boxes[i][0]), int(boxes[i][1])), cv2.FONT_HERSHEY_TRIPLEX,1, (255,0,0), 2, cv2.LINE_AA)\n","\n","  ax.set_axis_off()\n","  ax.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:39:13.567824Z","iopub.status.busy":"2024-04-19T13:39:13.567454Z","iopub.status.idle":"2024-04-19T13:39:13.574262Z","shell.execute_reply":"2024-04-19T13:39:13.573147Z","shell.execute_reply.started":"2024-04-19T13:39:13.567795Z"},"papermill":{"duration":0.137379,"end_time":"2024-03-01T22:39:02.664035","exception":false,"start_time":"2024-03-01T22:39:02.526656","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Averager:\n","    def __init__(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0\n","\n","    def send(self, value):\n","        self.current_total += value\n","        self.iterations += 1\n","\n","    @property\n","    def value(self):\n","        if self.iterations == 0:\n","            return 0\n","        else:\n","            return 1.0 * self.current_total / self.iterations\n","\n","    def reset(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-20T08:29:56.481992Z","iopub.status.busy":"2024-04-20T08:29:56.481497Z","iopub.status.idle":"2024-04-20T08:34:15.783734Z","shell.execute_reply":"2024-04-20T08:34:15.782636Z","shell.execute_reply.started":"2024-04-20T08:29:56.481953Z"},"trusted":true},"outputs":[],"source":["# # unzip model\n","\n","# import zipfile\n","# import os\n","\n","# zip_file_path = '/kaggle/input/faster-rcnn-all-txt-5/_output_.zip'\n","# extract_to = '/kaggle/working/'\n","\n","# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","#         zip_ref.extractall(extract_to)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-05T09:02:43.344650Z","iopub.status.busy":"2024-03-05T09:02:43.344096Z","iopub.status.idle":"2024-03-05T09:02:45.070123Z","shell.execute_reply":"2024-03-05T09:02:45.069040Z","shell.execute_reply.started":"2024-03-05T09:02:43.344607Z"},"trusted":true},"outputs":[],"source":["# Load Model\n","\n","# model = torch.load('/kaggle/working/mobilenet_bm_p5.pth')#,map_location=torch.device('cpu'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:40:47.439502Z","iopub.status.busy":"2024-04-19T13:40:47.438992Z","iopub.status.idle":"2024-04-19T13:40:47.456001Z","shell.execute_reply":"2024-04-19T13:40:47.455087Z","shell.execute_reply.started":"2024-04-19T13:40:47.439473Z"},"papermill":{"duration":0.152377,"end_time":"2024-03-01T22:39:02.901167","exception":false,"start_time":"2024-03-01T22:39:02.748790","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n","\n","num_epochs = 5  #Low epoch to save GPU time"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:39:21.149009Z","iopub.status.busy":"2024-04-19T13:39:21.148134Z","iopub.status.idle":"2024-04-19T13:39:21.158205Z","shell.execute_reply":"2024-04-19T13:39:21.157227Z","shell.execute_reply.started":"2024-04-19T13:39:21.148976Z"},"trusted":true},"outputs":[],"source":["def voc_ap(rec, prec, use_07_metric=True):\n","    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n","    Compute VOC AP given precision and recall.\n","    If use_07_metric is true, uses the\n","    VOC 07 11 point method (default:True).\n","    \"\"\"\n","    if use_07_metric:\n","        # 11 point metric\n","        ap = 0.\n","        for t in np.arange(0., 1.1, 0.1):\n","            if np.sum(rec >= t) == 0:\n","                p = 0\n","            else:\n","                p = np.max(prec[rec >= t])\n","            ap = ap + p / 11.\n","    else:\n","        # correct AP calculation\n","        # first append sentinel values at the end\n","        mrec = np.concatenate(([0.], rec, [1.]))\n","        mpre = np.concatenate(([0.], prec, [0.]))\n","\n","        # compute the precision envelope\n","        for i in range(mpre.size - 1, 0, -1):\n","            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n","\n","        # to calculate area under PR curve, look for points\n","        # where X axis (recall) changes value\n","        i = np.where(mrec[1:] != mrec[:-1])[0]\n","\n","        # and sum (\\Delta recall) * prec\n","        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n","    return ap\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T13:58:51.146436Z","iopub.status.busy":"2024-04-19T13:58:51.145671Z","iopub.status.idle":"2024-04-19T13:58:56.245974Z","shell.execute_reply":"2024-04-19T13:58:56.245099Z","shell.execute_reply.started":"2024-04-19T13:58:51.146400Z"},"papermill":{"duration":34.2718,"end_time":"2024-03-01T22:39:37.250379","exception":false,"start_time":"2024-03-01T22:39:02.978579","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["loss_hist = Averager()\n","itr = 1\n","lossHistoryiter = []\n","lossHistoryepoch = []\n","\n","mAP_Historyepoch = []\n","\n","ovthresh=0.5\n","use_07_metric=True\n","tp = 0\n","fp = 0\n","npos = 0\n","Total_score = 0\n","Total_overlaps = 0\n","best_mAP = 0\n","\n","import time\n","start = time.time()\n","import tqdm\n","for epoch in range(num_epochs):\n","    loss_hist.reset()\n","    \n","    model.train()\n","\n","    for images, targets, image_ids in tqdm.tqdm(train_data_loader):\n","\n","        images = list(image.float().to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","#         print(type(loss_dict))\n","        losses = sum(loss for loss in loss_dict.values())\n","        loss_value = losses.item()\n","\n","        loss_hist.send(loss_value)\n","        lossHistoryiter.append(loss_value)\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","        \n","        if itr % 50 == 0:\n","            print(f\"Iteration #{itr} loss: {loss_value}\",end=\"\\r\")\n","        itr += 1\n","\n","    # update the learning rate\n","    if lr_scheduler is not None:\n","        lr_scheduler.step()\n","    lossHistoryepoch.append(loss_hist.value)\n","    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")\n","    \n","    ## Validation\n","    model.eval()\n","    cpu_device = torch.device(\"cpu\")\n","\n","    for images, targets, image_ids in tqdm.tqdm(valid_data_loader):\n","        images = list(image.float().to(device) for image in images)\n","    #     targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","    #     outputs = model(images)\n","\n","        with torch.no_grad():\n","            outputs = model(images)\n","\n","        for tar,out in zip(targets,outputs):\n","    #         print(tar['boxes'].size(),out['boxes'].size())\n","            score = out['scores'].sum().cpu().detach().numpy()\n","    #         Total_score = Total_score + score\n","\n","            bb = tar['boxes'].cpu().detach().numpy()\n","            BBGT = out['boxes'].cpu().detach().numpy()\n","            ixmin = np.maximum(BBGT[:, 0], bb[0,0])\n","            iymin = np.maximum(BBGT[:, 1], bb[0,1])\n","            ixmax = np.minimum(BBGT[:, 2], bb[0,2])\n","            iymax = np.minimum(BBGT[:, 3], bb[0,3])\n","            iw = np.maximum(ixmax - ixmin, 0.)\n","            ih = np.maximum(iymax - iymin, 0.)\n","            inters = iw * ih\n","            uni = ((bb[0,2] - bb[0,0]) * (bb[0,3] - bb[0,1]) +\n","                    (BBGT[:, 2] - BBGT[:, 0]) *\n","                    (BBGT[:, 3] - BBGT[:, 1]) - inters)\n","            overlaps = inters / uni\n","    #         print(overlaps)\n","\n","            if overlaps.size==0:\n","                continue\n"," \n","            ovmax = np.max(overlaps)\n","            jmax = np.argmax(overlaps)\n","            if ovmax > ovthresh:\n","                tp+=1\n","            else:\n","                fp+=1\n","            npos+=bb.shape[0]\n","    rec = tp / float(npos)\n","    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n","    ap = voc_ap(rec, prec, use_07_metric)\n","    print(f\"Epoch #{epoch} mAP: {ap}\")\n","    mAP_Historyepoch.append(ap)\n","        \n","    # save best validation\n","    if best_mAP<ap:\n","        torch.save(model, '/kaggle/working/mobilenet_bm_p6.pth')\n","        best_mAP = ap\n","\n","end = time.time()\n","hours, rem = divmod(end-start, 3600)\n","minutes, seconds = divmod(rem, 60)\n","print(\"Time taken to Train the model :{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot training loss\n","import matplotlib.pyplot as plt\n","# x = [i for i in range(num_epochs)]\n","y = lossHistoryepoch\n","\n","# Plot scatter plot of training loss\n","x = np.arange(1, num_epochs+1)\n","colors = y  # Use loss values as colors\n","\n","plt.plot(x, y, marker='o', linestyle='-')#, color=plt.cm.viridis(colors))\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","# plt.colorbar(label='Loss')\n","plt.grid(True)\n","plt.show()\n","# plt.savefig('plot.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot validation mAP\n","import matplotlib.pyplot as plt\n","# x = [i for i in range(num_epochs)]\n","z = mAP_Historyepoch\n","\n","# Plot scatter plot of training loss\n","x = np.arange(1, num_epochs+1)\n","colors = y  # Use loss values as colors\n","\n","plt.plot(x, z, marker='o', linestyle='-')#, color=plt.cm.viridis(colors))\n","plt.xlabel('Epoch')\n","plt.ylabel('mAP')\n","plt.title('Validation mAP')\n","# plt.colorbar(label='Loss')\n","plt.grid(True)\n","plt.show()\n","# plt.savefig('plot.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:03:59.745783Z","iopub.status.busy":"2024-04-15T15:03:59.745105Z","iopub.status.idle":"2024-04-15T15:04:00.016794Z","shell.execute_reply":"2024-04-15T15:04:00.015886Z","shell.execute_reply.started":"2024-04-15T15:03:59.745742Z"},"papermill":{"duration":0.107572,"end_time":"2024-03-01T22:39:39.580796","exception":false,"start_time":"2024-03-01T22:39:39.473224","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["DIR_TEST = f'{DIR_INPUT}/test'\n","# test_df = pd.read_csv(f'{DIR_TEST}/_annotations.csv') #[:10]\n","test_df = read_dataset(DIR_TEST) \n","print(\"df Shape: \"+str(test_df.shape))\n","# print(\"No Of Classes: \"+str(test_df[\"class\"].nunique()))\n","# test_df['class_id']=1\n","test_df.sort_values(by='filename').head(10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:04:48.301275Z","iopub.status.busy":"2024-04-15T15:04:48.300916Z","iopub.status.idle":"2024-04-15T15:04:48.307836Z","shell.execute_reply":"2024-04-15T15:04:48.306926Z","shell.execute_reply.started":"2024-04-15T15:04:48.301248Z"},"papermill":{"duration":0.088854,"end_time":"2024-03-01T22:39:39.748180","exception":false,"start_time":"2024-03-01T22:39:39.659326","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# labels =  targets[1]['labels'].cpu().numpy()\n","model.eval()\n","cpu_device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:04:59.220227Z","iopub.status.busy":"2024-04-15T15:04:59.219298Z","iopub.status.idle":"2024-04-15T15:04:59.226599Z","shell.execute_reply":"2024-04-15T15:04:59.225577Z","shell.execute_reply.started":"2024-04-15T15:04:59.220186Z"},"papermill":{"duration":0.086948,"end_time":"2024-03-01T22:39:39.913719","exception":false,"start_time":"2024-03-01T22:39:39.826771","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_dataset = VinBigDataset(test_df, DIR_TEST, ToTensorV2(p=1.0))#,\"Test\")\n","\n","test_data_loader = DataLoader(\n","    test_dataset,\n","    batch_size= 8, # 8\n","    shuffle=False,\n","    num_workers=0,\n","    drop_last=False,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T07:08:36.085313Z","iopub.status.busy":"2024-03-12T07:08:36.084937Z","iopub.status.idle":"2024-03-12T07:08:36.089765Z","shell.execute_reply":"2024-03-12T07:08:36.088699Z","shell.execute_reply.started":"2024-03-12T07:08:36.085283Z"},"trusted":true},"outputs":[],"source":["del test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:05:03.578069Z","iopub.status.busy":"2024-04-15T15:05:03.577455Z","iopub.status.idle":"2024-04-15T15:05:03.583672Z","shell.execute_reply":"2024-04-15T15:05:03.582759Z","shell.execute_reply.started":"2024-04-15T15:05:03.578035Z"},"papermill":{"duration":0.088009,"end_time":"2024-03-01T22:39:40.078707","exception":false,"start_time":"2024-03-01T22:39:39.990698","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def format_prediction_string(labels, boxes, scores):\n","    pred_strings = []\n","    for j in zip(labels, scores, boxes):\n","        pred_strings.append(\"{0} {1:.4f} {2} {3} {4} {5}\".format(\n","            j[0], j[1], j[2][0], j[2][1], j[2][2], j[2][3]))\n","\n","    return \" \".join(pred_strings)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:05:12.539061Z","iopub.status.busy":"2024-04-15T15:05:12.538688Z","iopub.status.idle":"2024-04-15T15:05:13.930039Z","shell.execute_reply":"2024-04-15T15:05:13.929088Z","shell.execute_reply.started":"2024-04-15T15:05:12.539031Z"},"papermill":{"duration":1.589216,"end_time":"2024-03-01T22:39:41.745029","exception":false,"start_time":"2024-03-01T22:39:40.155813","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Test dataset sample\n","images,target, image_ids = next(iter(test_data_loader))\n","images = list(image.to(device) for image in images)\n","\n","for number in random.sample([1,2,3],3):\n","  img = images[number].permute(1,2,0).cpu().numpy()\n","  #labels= targets[number]['labels'].cpu().numpy().astype(np.int32)\n","  fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","  ax.set_axis_off()\n","  ax.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:05:36.385849Z","iopub.status.busy":"2024-04-15T15:05:36.385364Z","iopub.status.idle":"2024-04-15T15:05:36.906721Z","shell.execute_reply":"2024-04-15T15:05:36.905555Z","shell.execute_reply.started":"2024-04-15T15:05:36.385816Z"},"papermill":{"duration":1.479842,"end_time":"2024-03-01T22:39:43.322727","exception":false,"start_time":"2024-03-01T22:39:41.842885","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["### Test images\n","images,target, image_ids = next(iter(test_data_loader))\n","images = list(img.float().to(device) for img in images)\n","\n","outputs = model(images)\n","outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n","\n","\n","boxes = outputs[0]['boxes'].cpu().detach().numpy().astype(np.int32)\n","img = images[0].permute(1,2,0).cpu().detach().numpy()\n","labels= outputs[0]['labels'].cpu().detach().numpy().astype(np.int32)\n","score = outputs[0]['scores']\n","# print(score)\n","\n","fig, ax = plt.subplots(1,1,figsize=(16, 8))\n","\n","img = cv2.cvtColor(np.float32(img), cv2.COLOR_RGB2BGR)\n","for i in range(len(boxes)):\n","  img = cv2.rectangle(img,(boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize),(255,0,0),2)\n","  #print(le.inverse_transform([labels[i]-1])[0])\n","#   print(label_to_name(labels[i]), (boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize))\n","  # img = cv2.putText(img, label_to_name(labels[i]), (int(boxes[i][0]), int(boxes[i][1])), cv2.FONT_HERSHEY_TRIPLEX,3, (255,0,0), 3, cv2.LINE_AA)\n","t_boxes = target[0]['boxes'].cpu().detach().numpy().astype(np.int32)\n","for i in range(len(t_boxes)):\n","  img = cv2.rectangle(img,(t_boxes[i][0]+paddingSize,t_boxes[i][1]+paddingSize),(t_boxes[i][2]+paddingSize,t_boxes[i][3]+paddingSize),(0,0,255),2)\n","  \n","ax.set_axis_off()\n","ax.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T07:09:11.264725Z","iopub.status.busy":"2024-03-12T07:09:11.264343Z","iopub.status.idle":"2024-03-12T07:09:11.268933Z","shell.execute_reply":"2024-03-12T07:09:11.267976Z","shell.execute_reply.started":"2024-03-12T07:09:11.264699Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:25:48.161099Z","iopub.status.busy":"2024-04-15T15:25:48.160276Z","iopub.status.idle":"2024-04-15T15:29:22.658851Z","shell.execute_reply":"2024-04-15T15:29:22.657660Z","shell.execute_reply.started":"2024-04-15T15:25:48.161063Z"},"papermill":{"duration":7.697966,"end_time":"2024-03-01T22:39:51.390706","exception":false,"start_time":"2024-03-01T22:39:43.692740","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import time\n","import tqdm\n","\n","ovthresh=0.5\n","use_07_metric=True\n","tp = 0\n","fp = 0\n","npos = 0\n","\n","\n","Total_score = 0\n","Total_overlaps = 0\n","start = time.time()\n","for images, targets, image_ids in tqdm.tqdm(test_data_loader):\n","    images = list(image.float().to(device) for image in images)\n","#     targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","#     outputs = model(images)\n","\n","    with torch.no_grad():\n","        outputs = model(images)\n","        \n","    for tar,out in zip(targets,outputs):\n","#         print(tar['boxes'].size(),out['boxes'].size())\n","        score = out['scores'].sum().cpu().detach().numpy()\n","#         Total_score = Total_score + score\n","        \n","        bb = tar['boxes'].cpu().detach().numpy()\n","        BBGT = out['boxes'].cpu().detach().numpy()\n","        ixmin = np.maximum(BBGT[:, 0], bb[0,0])\n","        iymin = np.maximum(BBGT[:, 1], bb[0,1])\n","        ixmax = np.minimum(BBGT[:, 2], bb[0,2])\n","        iymax = np.minimum(BBGT[:, 3], bb[0,3])\n","        iw = np.maximum(ixmax - ixmin, 0.)\n","        ih = np.maximum(iymax - iymin, 0.)\n","        inters = iw * ih\n","        uni = ((bb[0,2] - bb[0,0]) * (bb[0,3] - bb[0,1]) +\n","                (BBGT[:, 2] - BBGT[:, 0]) *\n","                (BBGT[:, 3] - BBGT[:, 1]) - inters)\n","        overlaps = inters / uni\n","#         print(overlaps)\n","        Total_overlaps = Total_overlaps + overlaps.sum()\n","        \n","        if overlaps.size==0:\n","#             overlaps=[0]\n","            continue\n","#         else:\n","#             continue\n","        Total_score = Total_score + score\n","        ovmax = np.max(overlaps)\n","        jmax = np.argmax(overlaps)\n","        if ovmax > ovthresh:\n","            tp+=1\n","        else:\n","            fp+=1\n","        npos+=bb.shape[0]\n","        \n","\n","end = time.time()\n","hours, rem = divmod(end-start, 3600)\n","minutes, seconds = divmod(rem, 60)\n","print(\"Time taken to Test the model :{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n","\n","rec = tp / float(npos)\n","prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n","ap = voc_ap(rec, prec, use_07_metric)\n","IOU = Total_overlaps/npos\n","confidence = Total_score/npos"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-15T15:30:09.026434Z","iopub.status.busy":"2024-04-15T15:30:09.025620Z","iopub.status.idle":"2024-04-15T15:30:09.031455Z","shell.execute_reply":"2024-04-15T15:30:09.030396Z","shell.execute_reply.started":"2024-04-15T15:30:09.026401Z"},"papermill":{"duration":0.120741,"end_time":"2024-03-01T22:39:51.623227","exception":false,"start_time":"2024-03-01T22:39:51.502486","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["print('mean average precision:',ap)\n","print('confidence :',confidence)\n","print(\"IoU:\", IOU)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4741736,"sourceId":8042445,"sourceType":"datasetVersion"},{"datasetId":4741755,"sourceId":8042471,"sourceType":"datasetVersion"},{"datasetId":4742098,"sourceId":8042921,"sourceType":"datasetVersion"},{"datasetId":4742225,"sourceId":8043091,"sourceType":"datasetVersion"},{"datasetId":4742369,"sourceId":8043291,"sourceType":"datasetVersion"},{"datasetId":4742443,"sourceId":8043392,"sourceType":"datasetVersion"},{"datasetId":4742546,"sourceId":8043543,"sourceType":"datasetVersion"},{"datasetId":4742907,"sourceId":8044027,"sourceType":"datasetVersion"},{"datasetId":4763290,"sourceId":8072358,"sourceType":"datasetVersion"},{"datasetId":4788730,"sourceId":8107457,"sourceType":"datasetVersion"},{"sourceId":173390286,"sourceType":"kernelVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}

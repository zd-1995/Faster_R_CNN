{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-30T20:15:34.321240Z","iopub.status.busy":"2024-04-30T20:15:34.320877Z","iopub.status.idle":"2024-04-30T20:15:44.817809Z","shell.execute_reply":"2024-04-30T20:15:44.816740Z","shell.execute_reply.started":"2024-04-30T20:15:34.321211Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import os\n","import re\n","# import pydicom\n","import warnings\n","\n","from PIL import Image\n","import cv2\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","from albumentations.core.transforms_interface import ImageOnlyTransform\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data.sampler import SequentialSampler\n","\n","from matplotlib import pyplot as plt\n","import random\n","paddingSize= 0\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T20:15:50.813484Z","iopub.status.busy":"2024-04-30T20:15:50.812434Z","iopub.status.idle":"2024-04-30T20:19:08.374953Z","shell.execute_reply":"2024-04-30T20:19:08.373890Z","shell.execute_reply.started":"2024-04-30T20:15:50.813440Z"},"trusted":true},"outputs":[],"source":["# unzip model\n","\n","import zipfile\n","import os\n","\n","zip_file_path = '/kaggle/input/faster-resnet-p12/_output_.zip'\n","extract_to = '/kaggle/working/'\n","\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T20:19:28.892992Z","iopub.status.busy":"2024-04-30T20:19:28.892642Z","iopub.status.idle":"2024-04-30T20:19:29.419826Z","shell.execute_reply":"2024-04-30T20:19:29.418930Z","shell.execute_reply.started":"2024-04-30T20:19:28.892964Z"},"trusted":true},"outputs":[],"source":["# Load Model\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model = torch.load('/kaggle/working/resnet_bm_p12.pth')#,map_location=torch.device('cpu'))\n","model.to(device)\n","model.eval()\n","# cpu_device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T20:41:02.420983Z","iopub.status.busy":"2024-04-30T20:41:02.420192Z","iopub.status.idle":"2024-04-30T20:43:43.730663Z","shell.execute_reply":"2024-04-30T20:43:43.729723Z","shell.execute_reply.started":"2024-04-30T20:41:02.420950Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import torch\n","from torchvision import transforms\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.transforms.functional import to_tensor\n","from PIL import Image\n","\n","# Load the pre-trained Faster R-CNN model\n","# model = fasterrcnn_resnet50_fpn(pretrained=True)\n","# model.eval()\n","\n","# Define the device (CPU or GPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Open the input video file\n","cap = cv2.VideoCapture('/kaggle/input/drone-detection-test-videos-2/drone_video_19.mp4')\n","\n","# Get the video properties\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Define the codec and create a VideoWriter object\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('video_19.avi', fourcc, fps, (width, height))\n","\n","# Define the transformation to apply to each frame\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.ToTensor(),\n","])\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","        \n","    tensor_image = to_tensor(frame).unsqueeze(0).to(device)\n","\n","    # Convert the frame to a PIL image and apply the transformation\n","#     pil_image = Image.fromarray(frame)\n","#     tensor_image = transform(pil_image).unsqueeze(0).to(device)\n","\n","    # Perform object detection\n","    with torch.no_grad():\n","        output = model(tensor_image)\n","\n","    # Draw bounding boxes on the frame\n","    for box in output[0]['boxes']:\n","        box = [int(coord) for coord in box.cpu().numpy()]\n","        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n","\n","    # Write the frame with bounding boxes to the output video\n","    out.write(frame)\n","\n","# Release the VideoCapture and VideoWriter objects\n","cap.release()\n","out.release()\n","# cv2.destroyAllWindows()\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4889407,"sourceId":8242216,"sourceType":"datasetVersion"},{"datasetId":4895225,"sourceId":8250339,"sourceType":"datasetVersion"},{"datasetId":4904421,"sourceId":8262666,"sourceType":"datasetVersion"},{"sourceId":174754507,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
